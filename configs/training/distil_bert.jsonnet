{
    "max_tokens_count": 196,
    "batch_size": 32,
    "learning_rate": 0.00005,
    "num_warmup_steps": 1000,
    "num_training_steps": 100000,
    "model": {
        "vocab_size": 119547,
        "n_layers": 3
    }
}
